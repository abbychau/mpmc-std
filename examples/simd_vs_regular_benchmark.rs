use std::sync::Arc;
use std::thread;
use std::time::Instant;

#[cfg(feature = "simd")]
use mpmc_std::simd_queue::{SimdMpmcQueue, SimdProducer, SimdConsumer};
use mpmc_std::{MpmcQueue, Producer, Consumer};

fn main() {
    println!("üî• SIMD vs Regular Queue Performance Benchmark");
    println!("==============================================");
    
    #[cfg(feature = "simd")]
    {
        run_comprehensive_benchmark();
    }
    
    #[cfg(not(feature = "simd"))]
    {
        println!("‚ùå SIMD features not enabled!");
        println!("Run with: cargo run --features simd --example simd_vs_regular_benchmark");
    }
}

#[cfg(feature = "simd")]
fn run_comprehensive_benchmark() {
    println!("\nüìä Testing different scenarios with 100,000 operations each\n");

    // Test 1: Single-threaded batch operations
    println!("1. Single-threaded Batch Operations (groups of 4)");
    println!("   Testing optimal SIMD scenario...");
    
    let iterations = 25_000; // 25k * 4 = 100k total items
    
    // SIMD Queue - batch operations
    let simd_queue = Arc::new(SimdMpmcQueue::<u64>::new(1024));
    let simd_producer = SimdProducer::new(Arc::clone(&simd_queue));
    let simd_consumer = SimdConsumer::new(Arc::clone(&simd_queue));
    
    let start = Instant::now();
    for i in 0..iterations {
        let batch = vec![(i*4) as u64, (i*4+1) as u64, (i*4+2) as u64, (i*4+3) as u64];
        while simd_producer.send(&batch).is_err() {
            let mut recv_buffer = vec![0u64; 4];
            simd_consumer.recv(&mut recv_buffer);
        }
    }
    
    // Receive all remaining
    let mut total_received = 0;
    let mut recv_buffer = vec![0u64; 100];
    while total_received < iterations * 4 {
        let received = simd_consumer.recv(&mut recv_buffer);
        if received == 0 { break; }
        total_received += received;
    }
    
    let simd_duration = start.elapsed();
    let simd_ops_sec = (iterations * 4 * 2) as f64 / simd_duration.as_secs_f64();
    
    // Regular Queue - same pattern
    let regular_queue = Arc::new(MpmcQueue::<u64>::new(1024));
    let regular_producer = Producer::new(Arc::clone(&regular_queue));
    let regular_consumer = Consumer::new(Arc::clone(&regular_queue));
    
    let start = Instant::now();
    for i in 0..iterations {
        for j in 0..4 {
            while regular_producer.send((i*4 + j) as u64).is_err() {
                regular_consumer.recv();
            }
        }
    }
    
    // Receive all remaining
    while regular_consumer.recv().is_some() {}
    
    let regular_duration = start.elapsed();
    let regular_ops_sec = (iterations * 4 * 2) as f64 / regular_duration.as_secs_f64();
    
    let improvement = (simd_ops_sec / regular_ops_sec - 1.0) * 100.0;
    
    println!("   SIMD:    {:.0} ops/sec ({:.2}ms)", simd_ops_sec, simd_duration.as_millis());
    println!("   Regular: {:.0} ops/sec ({:.2}ms)", regular_ops_sec, regular_duration.as_millis());
    println!("   Result:  {:+.1}% performance change\n", improvement);

    // Test 2: Mixed batch sizes (more realistic)
    println!("2. Mixed Batch Sizes (1,2,3,4,5,6,7 items per batch)");
    println!("   Testing adaptive SIMD behavior...");
    
    let iterations = 14_285; // ~100k items total
    
    // SIMD Queue
    let start = Instant::now();
    for i in 0..iterations {
        let batch_size = (i % 7) + 1;
        let batch: Vec<u64> = (0..batch_size).map(|j| (i * 10 + j) as u64).collect();
        while simd_producer.send(&batch).is_err() {
            let mut recv_buffer = vec![0u64; 10];
            simd_consumer.recv(&mut recv_buffer);
        }
    }
    
    let mut total_received = 0;
    let mut recv_buffer = vec![0u64; 100];
    while total_received < 400_000 { // approximate total
        let received = simd_consumer.recv(&mut recv_buffer);
        if received == 0 { break; }
        total_received += received;
    }
    
    let simd_mixed_duration = start.elapsed();
    let simd_mixed_ops_sec = (total_received * 2) as f64 / simd_mixed_duration.as_secs_f64();
    
    // Regular Queue - same pattern
    let start = Instant::now();
    let mut total_sent = 0;
    for i in 0..iterations {
        let batch_size = (i % 7) + 1;
        for j in 0..batch_size {
            while regular_producer.send((i * 10 + j) as u64).is_err() {
                regular_consumer.recv();
            }
            total_sent += 1;
        }
    }
    
    while regular_consumer.recv().is_some() {}
    
    let regular_mixed_duration = start.elapsed();
    let regular_mixed_ops_sec = (total_sent * 2) as f64 / regular_mixed_duration.as_secs_f64();
    
    let mixed_improvement = (simd_mixed_ops_sec / regular_mixed_ops_sec - 1.0) * 100.0;
    
    println!("   SIMD:    {:.0} ops/sec ({:.2}ms)", simd_mixed_ops_sec, simd_mixed_duration.as_millis());
    println!("   Regular: {:.0} ops/sec ({:.2}ms)", regular_mixed_ops_sec, regular_mixed_duration.as_millis());
    println!("   Result:  {:+.1}% performance change\n", mixed_improvement);

    // Test 3: Multi-threaded contention
    println!("3. Multi-threaded Contention (2 producers, 2 consumers)");
    println!("   Testing SIMD under contention...");
    
    let iterations_per_thread = 12_500; // 4 threads * 12.5k = 50k ops per thread
    
    // SIMD Multi-threaded
    let simd_queue = Arc::new(SimdMpmcQueue::<u64>::new(512));
    let start = Instant::now();
    
    let mut handles = Vec::new();
    
    // 2 producers
    for thread_id in 0..2 {
        let producer = SimdProducer::new(Arc::clone(&simd_queue));
        handles.push(thread::spawn(move || {
            for i in 0..iterations_per_thread {
                let batch = vec![(thread_id * 100000 + i) as u64; 4];
                while producer.send(&batch).is_err() {
                    thread::yield_now();
                }
            }
        }));
    }
    
    // 2 consumers
    for _ in 0..2 {
        let consumer = SimdConsumer::new(Arc::clone(&simd_queue));
        handles.push(thread::spawn(move || {
            let mut buffer = vec![0u64; 8];
            for _ in 0..iterations_per_thread {
                while consumer.recv(&mut buffer) == 0 {
                    thread::yield_now();
                }
            }
        }));
    }
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    let simd_mt_duration = start.elapsed();
    let simd_mt_ops_sec = (iterations_per_thread * 4 * 4 * 2) as f64 / simd_mt_duration.as_secs_f64();
    
    // Regular multi-threaded
    let regular_queue = Arc::new(MpmcQueue::<u64>::new(512));
    let start = Instant::now();
    
    let mut handles = Vec::new();
    
    // 2 producers
    for thread_id in 0..2 {
        let producer = Producer::new(Arc::clone(&regular_queue));
        handles.push(thread::spawn(move || {
            for i in 0..iterations_per_thread * 4 { // Same total items
                while producer.send((thread_id * 100000 + i) as u64).is_err() {
                    thread::yield_now();
                }
            }
        }));
    }
    
    // 2 consumers  
    for _ in 0..2 {
        let consumer = Consumer::new(Arc::clone(&regular_queue));
        handles.push(thread::spawn(move || {
            for _ in 0..iterations_per_thread * 4 {
                while consumer.recv().is_none() {
                    thread::yield_now();
                }
            }
        }));
    }
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    let regular_mt_duration = start.elapsed();
    let regular_mt_ops_sec = (iterations_per_thread * 4 * 4 * 2) as f64 / regular_mt_duration.as_secs_f64();
    
    let mt_improvement = (simd_mt_ops_sec / regular_mt_ops_sec - 1.0) * 100.0;
    
    println!("   SIMD:    {:.0} ops/sec ({:.2}ms)", simd_mt_ops_sec, simd_mt_duration.as_millis());
    println!("   Regular: {:.0} ops/sec ({:.2}ms)", regular_mt_ops_sec, regular_mt_duration.as_millis());
    println!("   Result:  {:+.1}% performance change\n", mt_improvement);

    // Test 4: Different data types
    println!("4. Different 64-bit Data Types");
    println!("   Testing SIMD with various types...");
    
    let test_iterations = 10_000;
    
    // Test i64
    let i64_queue = Arc::new(SimdMpmcQueue::<i64>::new(256));
    let i64_producer = SimdProducer::new(Arc::clone(&i64_queue));
    let i64_consumer = SimdConsumer::new(Arc::clone(&i64_queue));
    
    let start = Instant::now();
    for i in 0..test_iterations {
        let batch = vec![-i as i64, -(i+1) as i64, -(i+2) as i64, -(i+3) as i64];
        i64_producer.send(&batch).unwrap();
    }
    let mut recv_buffer = vec![0i64; 40000];
    i64_consumer.recv(&mut recv_buffer);
    let i64_duration = start.elapsed();
    let i64_ops_sec = (test_iterations * 4 * 2) as f64 / i64_duration.as_secs_f64();
    
    // Test f64
    let f64_queue = Arc::new(SimdMpmcQueue::<f64>::new(256));
    let f64_producer = SimdProducer::new(Arc::clone(&f64_queue));
    let f64_consumer = SimdConsumer::new(Arc::clone(&f64_queue));
    
    let start = Instant::now();
    for i in 0..test_iterations {
        let batch = vec![i as f64 + 0.1, i as f64 + 0.2, i as f64 + 0.3, i as f64 + 0.4];
        f64_producer.send(&batch).unwrap();
    }
    let mut recv_buffer = vec![0.0f64; 40000];
    f64_consumer.recv(&mut recv_buffer);
    let f64_duration = start.elapsed();
    let f64_ops_sec = (test_iterations * 4 * 2) as f64 / f64_duration.as_secs_f64();
    
    println!("   i64 SIMD: {:.0} ops/sec ({:.2}ms)", i64_ops_sec, i64_duration.as_millis());
    println!("   f64 SIMD: {:.0} ops/sec ({:.2}ms)", f64_ops_sec, f64_duration.as_millis());
    
    // Summary
    println!("\nüéØ BENCHMARK SUMMARY:");
    println!("   =====================");
    println!("   1. Optimal batches (4 items):     {:+.1}%", improvement);
    println!("   2. Mixed batch sizes:              {:+.1}%", mixed_improvement);  
    println!("   3. Multi-threaded contention:     {:+.1}%", mt_improvement);
    println!("   4. Different types work correctly ‚úì");
    
    if improvement > 0.0 || mixed_improvement > 0.0 || mt_improvement > 0.0 {
        println!("\n‚úÖ SIMD provides performance benefits in at least one scenario!");
    } else {
        println!("\n‚ö†Ô∏è  SIMD overhead may exceed benefits in current test conditions.");
        println!("    SIMD benefits typically emerge with higher contention or larger datasets.");
    }
    
    println!("\nüí° Key findings:");
    println!("   ‚Ä¢ SIMD automatically optimizes groups of 4 elements");
    println!("   ‚Ä¢ Works transparently with any 64-bit data type");
    println!("   ‚Ä¢ Performance varies by workload and contention level");
    println!("   ‚Ä¢ No manual batch management required");
}