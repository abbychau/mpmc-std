<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üî¨ Implementation Deep Dive - MPMC Queue</title>
    <link rel="stylesheet" href="shared-styles.css">

</head>
<body>
    <div class="container">
        <div class="header">
            <a href="https://github.com/abbychau/mpmc-std" class="github-corner" target="_blank" rel="noopener noreferrer">
                <svg xmlns="http://www.w3.org/2000/svg" width="80" height="80" viewBox="0 0 250 250" fill="#151513" style="position: absolute; top: 0; right: 0">
                <path d="M0 0l115 115h15l12 27 108 108V0z" fill="#000"/>
                <path class="octo-arm" d="M128 109c-15-9-9-19-9-19 3-7 2-11 2-11-1-7 3-2 3-2 4 5 2 11 2 11-3 10 5 15 9 16" style="-webkit-transform-origin: 130px 106px; transform-origin: 130px 106px"/>
                <path class="octo-body" d="M115 115s4 2 5 0l14-14c3-2 6-3 8-3-8-11-15-24 2-41 5-5 10-7 16-7 1-2 3-7 12-11 0 0 5 3 7 16 4 2 8 5 12 9s7 8 9 12c14 3 17 7 17 7-4 8-9 11-11 11 0 6-2 11-7 16-16 16-30 10-41 2 0 3-1 7-5 11l-12 11c-1 1 1 5 1 5z"/>
                </svg>
            </a>
            <h1>üî¨ Implementation Deep Dive</h1>
            <p>Technical details and performance engineering</p>
        </div>
        
        <div class="content">
            <div style="text-align: center; margin-bottom: 2rem;">
                <a href="index.html" class="nav-back">‚Üê Back to Documentation Index</a>
            </div>
<h1>Implementation Details</h1>
<p>This document explains the key implementation decisions and technical details of the lockless MPMC queue.</p>
<h2>Core Algorithm</h2>
<h3>Sequence-Based Coordination</h3>
<p>The algorithm uses sequence numbers instead of flags for coordination:</p>
<br>
<pre><code class="language-rust">
struct Slot&lt;T&gt; {
    sequence: AtomicUsize,              // Single coordination point
    data: UnsafeCell&lt;MaybeUninit&lt;T&gt;&gt;,   // Raw storage
}
</code></pre>
<br>
<p><strong>Benefits:</strong></p>
<ul>
<li>ABA immunity: sequences always advance</li>
<li>Single atomic operation for state check</li>
<li>Natural ordering guarantees</li>
<li>Wait-free progress bounds</li>
</ul>
<h3>Memory Ordering</h3>
<p>Careful memory ordering ensures correctness:</p>
<ul>
<li><strong>Relaxed</strong>: Position loads (just need current value)</li>
<li><strong>Acquire</strong>: Sequence loads (see previous writes)</li>
<li><strong>Release</strong>: Sequence stores (make writes visible)</li>
</ul>
<br>
<pre><code class="language-rust">
// Producer stores data BEFORE updating sequence
unsafe { (*slot.data.get()).write(item); }
slot.sequence.store(new_seq, Ordering::Release);
</code></pre>
<h3>ABA Problem Prevention</h3>
<p>Sequence numbers prevent the ABA problem by always advancing:</p>
<br>
<pre><code>
Slot 0: 0 ‚Üí 1 ‚Üí 8 ‚Üí 9 ‚Üí 16 ‚Üí 17 ‚Üí ...
        ‚Üë   ‚Üë   ‚Üë   ‚Üë    ‚Üë    ‚Üë
       Init Prod Cons Prod Cons Prod
</code></pre>
<br>
<p>Even if the same logical state occurs, the sequence number is different.</p>
<h2>Power-of-2 Optimization</h2>
<p>Capacity is rounded to power-of-2 for fast indexing:</p>
<br>
<pre><code class="language-rust">
// Instead of expensive modulo:
position % capacity  // ~20-40 cycles
// Use fast bitwise AND:
position &amp; mask      // ~1 cycle
// Example: capacity=1024, mask=1023
// 5000 % 1024 = 904  (slow)
// 5000 &amp; 1023 = 904  (fast)
</code></pre>
<br>
<p>Capacity is automatically rounded up to the next power-of-2.</p>
<h2>Cache-Line Alignment</h2>
<p>Prevents false sharing by separating producer and consumer positions:</p>
<br>
<pre><code class="language-rust">
#[repr(align(64))]  // 64-byte cache line alignment
struct ProducerPos {
    head: AtomicUsize,
    // 56 bytes padding
}
#[repr(align(64))]
struct ConsumerPos {
    tail: AtomicUsize, 
    // 56 bytes padding
}
</code></pre>
<br>
<p><strong>Benefit</strong>: ~40% performance improvement by eliminating cache invalidations between cores.</p>
<h2>Atomic Operations</h2>
<h3>Compare-Exchange-Weak</h3>
<p>Uses <code>compare<em>exchange</em>weak</code> instead of strong version:</p>
<ul>
<li>More efficient on ARM/PowerPC architectures</li>
<li>Allows spurious failures (acceptable since we're in retry loops)</li>
<li>Better power consumption</li>
</ul>
<h3>Memory Ordering Strategy</h3>
<ul>
<li><strong>Relaxed</strong>: Position loads (no synchronization needed)</li>
<li><strong>Acquire</strong>: Sequence loads (see previous writes)</li>
<li><strong>Release</strong>: Sequence stores (make writes visible)</li>
<li><strong>Avoids SeqCst</strong>: Too expensive for this use case</li>
</ul>
<h2>Memory Safety</h2>
<p>Achieves memory safety without garbage collection:</p>
<br>
<pre><code class="language-rust">
struct Slot&lt;T&gt; {
    sequence: AtomicUsize,              // Coordination
    data: UnsafeCell&lt;MaybeUninit&lt;T&gt;&gt;,   // Safe uninitialized storage
}
</code></pre>
<br>
<p><strong>Safety invariants:</strong></p>
<ol>
<li>Data written only when sequence == expected</li>
<li>Data read only when sequence == expected + 1</li>
<li>Sequence coordination prevents access races</li>
<li>Proper cleanup in Drop implementation</li>
</ol>
<br>
<p><strong>Send/Sync traits</strong>: Safely implemented using sequence coordination to prevent data races.</p>
<h2>Performance Optimizations</h2>
<h3>Branch Prediction</h3>
<p>Code structure favors common case (successful operations) to help CPU branch predictor.</p>
<h3>CPU Cache Utilization</h3>
<ul>
<li>Sequential ring buffer access patterns enable prefetching</li>
<li>Temporal locality: threads access consecutive slots</li>
<li>Spatial locality: 64-byte alignment fits cache boundaries</li>
<li>Each position gets own cache line to prevent false sharing</li>
</ul>
<h2>Common Pitfalls</h2>
<h3>Sequence Number Overflow</h3>
<p>Wrapping arithmetic is intentional and safe - maintains ordering even when numbers wrap around.</p>
<h3>Memory Ordering</h3>
<p>Critical to use <code>Release</code> ordering when storing sequences to make data writes visible.</p>
<h3>Capacity Requirements</h3>
<p>Capacity is automatically rounded up to next power-of-2 for optimal performance.</p>
<h2>Performance Tips</h2>
<h3>Profiling</h3>
<ul>
<li>Monitor cache miss rate (<5% is good)</li>
<li>Check branch prediction accuracy (>95% is good)</li>
<li>Watch cycles per instruction (<2.0 is good)</li>
</ul>
<h3>Common Issues</h3>
<ul>
<li><strong>Too small capacity</strong>: Increase size to reduce contention</li>
<li><strong>Too many threads</strong>: Consider multiple queues with >8 threads</li>
<li><strong>Large items</strong>: Use <code>Arc<T></code> or <code>Box<T></code> for indirect storage</li>
</ul>
<h3>Debugging</h3>
<pre><code class="language-rust">
// Queue provides introspection methods
queue.capacity();  // Power-of-2 capacity
queue.len();       // Approximate current length
queue.is_empty();  // Snapshot view
queue.is_full();   // Snapshot view
</code></pre>
        </div>
        
        <div class="nav-grid">
            <div class="nav-card">
                <p>Explore the complete technical documentation suite for the MPMC Queue implementation.</p>
                <div style="display: flex; gap: 1rem; margin-top: 1.5rem;">
                    <a href="index.html" style="flex: 1; text-align: center;">Documentation Index</a>
                    <a href="COMPARATIVE_ANALYSIS.html" style="flex: 1; text-align: center;">Comparative Analysis</a>
                </div>
            </div>
        </div>
    </div>

    <div class="footer">
        <div class="footer-brand">MPMC Queue - High-Performance Lockless Data Structure</div>
        <p>Built with Rust ‚Ä¢ Benchmarked with Criterion.rs ‚Ä¢ Optimized for Modern Hardware</p>
        <p style="font-size: 0.9rem; margin-top: 1rem;">
            Research-grade implementation combining Michael & Scott, LMAX Disruptor, and modern optimization techniques
        </p>
    </div>
</body>
</html>
